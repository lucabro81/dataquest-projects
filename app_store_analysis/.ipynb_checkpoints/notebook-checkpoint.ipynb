{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# App store data market analysis\n",
    "\n",
    "Abbiamo sti due csv, uno da Apple store e uno da Play store, vediamo cosa c'è dentro.\n",
    "\n",
    "Apriamo e salviamo i csv in due liste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "\n",
    "ios_apps_data = list(reader(open('./AppleStore.csv')))\n",
    "android_apps_data = list(reader(open('./googleplaystore.csv')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passiamo ora alla pulitura dei dati\n",
    "\n",
    "### Eliminazione dati incompleti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10840\n"
     ]
    }
   ],
   "source": [
    "android_header = android_apps_data[0];\n",
    "ios_header = ios_apps_data[0];\n",
    "\n",
    "length_android_header = len(android_header)\n",
    "length_ios_header = len(ios_header)\n",
    "\n",
    "android_apps_data = android_apps_data[1:]\n",
    "ios_apps_data = ios_apps_data[1:]\n",
    "\n",
    "index = 0\n",
    "for row in android_apps_data:\n",
    "    if len(row) < length_android_header:\n",
    "        del android_apps_data[index]\n",
    "    else:\n",
    "        index += 1\n",
    "        \n",
    "print(len(android_apps_data))\n",
    "        \n",
    "index = 0\n",
    "for row in ios_apps_data:\n",
    "    if len(row) < length_ios_header:\n",
    "        del ios_apps_data[index]\n",
    "    else:\n",
    "        index += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tables Header\n",
    "\n",
    "| Index | Android        | iOS              |\n",
    "|:-----:|:--------------:|:-----------------:\n",
    "|0      | App            | id               |\n",
    "|1      | Category       | track_name       |\n",
    "|2      | Rating         | size_bytes       |\n",
    "|3      | Reviews        | currency         |\n",
    "|4      | Size           | price            |\n",
    "|5      | Installs       | rating_count_tot |\n",
    "|6      | Type           | rating_count_ver |\n",
    "|7      | Price          | user_rating      |\n",
    "|8      | Content Rating | user_rating_ver  |\n",
    "|9      | Genres         | ver              |\n",
    "|10     | Last Updated   | cont_rating      |\n",
    "|11     | Current Ver    | prime_genre      |\n",
    "|12     | Android Ver    | sup_devices.num  |\n",
    "|13     | -              | ipadSc_urls.num  |\n",
    "|14     | -              | lang.num         |\n",
    "|15     | -              | vpp_lic          |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recupero dati duplicati\n",
    "\n",
    "Questa funzione salva in un dictionary le frequenze assolute di ogni applicazione duplicata.\n",
    "In ingresso prende il data set e l'indice della colonna usata per determinare i duplicati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_app_freq(apps_data, key_index = 0):\n",
    "    duplicates_dict = {}\n",
    "    unique_dict = {}\n",
    "\n",
    "    for row in apps_data[1:]:\n",
    "        dict_key = row[key_index]\n",
    "        if (dict_key not in duplicates_dict):\n",
    "            duplicates_dict[dict_key] = []\n",
    "        duplicates_dict[dict_key].append(row)\n",
    "    return duplicates_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questa invece salva le frequenze solo se effettivamente duplicate, quindi se una certa app viene vista 2 o più volte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_duplicates(apps_data, key_index = 0):\n",
    "    duplicates_dict = {}\n",
    "    unique_dict = {}\n",
    "\n",
    "    for row in apps_data[1:]:\n",
    "        dict_key = row[key_index]\n",
    "        if (dict_key in unique_dict):\n",
    "            if (dict_key not in duplicates_dict):\n",
    "                duplicates_dict[dict_key] = [unique_dict[dict_key]]\n",
    "            duplicates_dict[dict_key].append(row)\n",
    "        else:\n",
    "            unique_dict[dict_key] = row\n",
    "    return duplicates_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "salvo le frequenze recuperate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates_freq_ios = get_app_freq(ios_apps_data, 1)\n",
    "duplicates_freq_android = get_app_freq(android_apps_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questa invece permette di stampare le frequenze recuperate con la funzione precedente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_duplicates(duplicates_dict, info_key = 3, info_string = 'Info'):\n",
    "    for key in duplicates_dict:\n",
    "        duplicate = duplicates_dict[key]\n",
    "        n_apps = len(duplicate)\n",
    "        info_str = ''\n",
    "        for app in duplicate:\n",
    "            info_str += '\\t' + app[info_key]\n",
    "\n",
    "        print(key + '\\n' + info_string + info_str + '\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminazione duplicati\n",
    "\n",
    "Per la rimozione dei duplicati si utilizzerà la strategia di confrontare il numero di review, chi ne ha di più rimane. La seguente funzione prende in ingresso i dati da ripulire e la colonna da utilizzare per confrontare i duplicati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(apps_freq, column = 3):\n",
    "    data_clean = []\n",
    "    for key in apps_freq:\n",
    "        duplicate_freq = apps_freq[key]\n",
    "        # se duplicati confrontare la colonna in column\n",
    "        if len(duplicate_freq) > 1:\n",
    "            duplicate_freq.sort(key = lambda duplicate_freq: duplicate_freq[column], reverse = True)\n",
    "        data_clean.append(duplicate_freq[0])\n",
    "            \n",
    "    return data_clean\n",
    "            \n",
    "android_clean = remove_duplicates(duplicates_freq_android)\n",
    "ios_clean = remove_duplicates(duplicates_freq_ios, 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminazione data set in cui il nome app contiene caratteri non latini\n",
    "\n",
    "La strategia è quella di elminare le app nel cui nome appaiono più di 3 volte caratteri considerati non latini (quindi no kanji, emoji, rune naniche...). Da perfezionare ovviamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_strange_name(apps_data, character_range, column = 0):\n",
    "    \n",
    "    cleaned = []\n",
    "    \n",
    "    for row in apps_data:\n",
    "        \n",
    "        name = row[column]\n",
    "        \n",
    "        char_count = 0\n",
    "        is_addable = True\n",
    "        \n",
    "        for char in name:\n",
    "            if (ord(char) not in character_range):\n",
    "                char_count += 1\n",
    "                if char_count > 3:\n",
    "                    is_addable = False\n",
    "                    \n",
    "        if (is_addable):\n",
    "            cleaned.append(row)\n",
    "            \n",
    "    return cleaned\n",
    "\n",
    "android_no_strange_name = remove_strange_name(android_clean, range(0,127))\n",
    "ios_no_strange_name = remove_strange_name(ios_clean, range(0,127), 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolamento app free"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_free_app(apps_data, column = 7):\n",
    "    free_apps = []\n",
    "    index = 0\n",
    "    for row in apps_data:\n",
    "        price = 0\n",
    "        index += 1\n",
    "        if ('$' in row[column]):\n",
    "            price = float(row[column][1:])\n",
    "        else:\n",
    "            price = float(row[column])\n",
    "            \n",
    "        if price == 0:\n",
    "            free_apps.append(row)\n",
    "    return free_apps\n",
    "\n",
    "android_free = get_free_app(android_no_strange_name)\n",
    "ios_free = get_free_app(ios_no_strange_name, 4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation strategy\n",
    "To minimize risks and overhead, our validation strategy for an app idea is comprised of three steps:\n",
    "\n",
    "Build a minimal Android version of the app, and add it to Google Play.\n",
    "If the app has a good response from users, we develop it further.\n",
    "If the app is profitable after six months, we build an iOS version of the app and add it to the App Store.\n",
    "Because our end goal is to add the app on both Google Play and the App Store, we need to find app profiles that are successful on both markets. For instance, a profile that works well for both markets might be a productivity app that makes use of gamification.\n",
    "\n",
    "Let's begin the analysis by getting a sense of what are the most common genres for each market. For this, we'll need to build frequency tables for a few columns in our data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def freq_table(dataset, column):\n",
    "    freq_dict = {}\n",
    "    for row in dataset:\n",
    "        label = row[column]\n",
    "        if label in freq_dict:\n",
    "            freq_dict[label] += 1\n",
    "        else:\n",
    "            freq_dict[label] = 1\n",
    "    return freq_dict\n",
    "\n",
    "def set_tab(collection, tab_n, index):\n",
    "    \n",
    "    max_str_length_arr = [];\n",
    "    max_tab_arr = []\n",
    "    \n",
    "    # con ua lambda si determina se è un dizionario, in quel caso si usa quella in posizione 0\n",
    "    get_item = (lambda key: [key] + collection[key], lambda item: item);\n",
    "    getter = get_item[0] if (isinstance(collection, dict)) else get_item[1]\n",
    "    \n",
    "    # trovo la lunghezza massima tra le stringhe nella collezione di dati passata\n",
    "    for item in collection:\n",
    "        item = getter(item)\n",
    "        print(item)\n",
    "        i = 0\n",
    "        for entry in item:\n",
    "            current_len = len(str(entry))\n",
    "            if (i > (len(max_str_length_arr)-1)):\n",
    "                max_str_length_arr.append(0)\n",
    "            if (current_len > max_str_length_arr[i]):\n",
    "                max_str_length_arr[i] = current_len\n",
    "            i += 1\n",
    "    \n",
    "    # numero di tab mecessari a comprendere le stringhe massima trovate nel ciclo prima\n",
    "    for length in max_str_length_arr:\n",
    "        max_tab_arr.append(math.ceil(length/tab_n))\n",
    "        \n",
    "    # si copletano la stringhe con il numero giusto di tab\n",
    "    string_arr_augmented = []\n",
    "    \n",
    "    for item in collection:\n",
    "        item = getter(item)\n",
    "        tabbed_arr = [item]\n",
    "        i = 0\n",
    "        for entry in item:\n",
    "            \n",
    "            # numero di tab mecessari per singola parola\n",
    "            curr_tab = math.floor(len(str(entry))/tab_n)\n",
    "            print(entry, len(str(entry)), max_tab_arr[i], curr_tab)\n",
    "            # calcolo differenza con la parola maggiore per aggiungere i tab che restano\n",
    "            tabbed_arr.append(str(entry) + '\\t'*(max_tab_arr[i]-curr_tab))\n",
    "            \n",
    "            i += 1\n",
    "        string_arr_augmented.append(tabbed_arr)\n",
    "        print('#############')\n",
    "        \n",
    "    return string_arr_augmented\n",
    "            \n",
    "    \n",
    "\n",
    "def display_table(dataset, index):\n",
    "    table = freq_table(dataset, index)\n",
    "    table_display = []\n",
    "    for key in table:\n",
    "        tuple_from_table = (key, table[key])\n",
    "        table_display.append(tuple_from_table)\n",
    "        \n",
    "    table_display.sort(key = lambda table_display: table_display[1], reverse = True)\n",
    "    tabbed_table = set_tab(table_display, 8, 0);\n",
    "    \n",
    "    for entry in tabbed_table:\n",
    "        print(entry[1], entry[2])\n",
    "        \n",
    "def display_dict(dictonary, header = [], index = -1):\n",
    "    \n",
    "    tabbed_table = set_tab(dictonary, 8, 0);\n",
    "    \n",
    "    for entry in tabbed_table:\n",
    "        print(entry[1], entry[2], entry[3])\n",
    "    \n",
    "        \n",
    "# display_table(android_clean, 1)\n",
    "# display_table(ios_clean, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3], [1, 2, 3], [1, 2, 3]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "freq_prime_genres = freq_table(ios_clean, 11)\n",
    "\n",
    "freq_genres_installation = {}\n",
    "\n",
    "for row in ios_clean:\n",
    "    genre = row[11]\n",
    "    rating_count_tot = int(row[5])\n",
    "    if genre in freq_genres_installation:\n",
    "        freq_genres_installation[genre][0] += rating_count_tot\n",
    "    else:\n",
    "        freq_genres_installation[genre] = [rating_count_tot, freq_prime_genres[genre]]\n",
    "        \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame(np.random.random(200).reshape(2, 100))\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
